{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning de Hiperparámetros - Random Forest\n",
    "## Predicción de Características de Vuelo en Planeador\n",
    "\n",
    "**Objetivo:** Optimizar hiperparámetros de RF para maximizar R² en targets problemáticos\n",
    "\n",
    "**Autor:** Estanislao  \n",
    "**Fecha:** Diciembre 2024\n",
    "\n",
    "---\n",
    "\n",
    "## Estrategia\n",
    "\n",
    "1. **Grid Search** en espacio de hiperparámetros\n",
    "2. **Foco especial** en targets problemáticos:\n",
    "   - intensidad_termicas_mean_ms\n",
    "   - tasa_ascenso_mean_ms\n",
    "3. **Trade-off**: Performance vs Overfitting\n",
    "4. **Justificación** de hiperparámetros finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "sys.path.append('../01_Preprocesamiento')\n",
    "from eda_functions import configurar_visualizacion\n",
    "from modelo_utils import preparar_datos, evaluar_modelo\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "configurar_visualizacion()\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.read_csv('../data/processed/dev.csv', index_col=0)\n",
    "test = pd.read_csv('../data/processed/test.csv', index_col=0)\n",
    "\n",
    "targets_reg = [\n",
    "    'altura_max_m', 'ganancia_altura_m', 'duracion_min',\n",
    "    'distancia_km', 'velocidad_promedio_kmh', 'num_termicas',\n",
    "    'intensidad_termicas_mean_ms', 'tiempo_en_termicas_min',\n",
    "    'tasa_ascenso_mean_ms'\n",
    "]\n",
    "\n",
    "# Targets problemáticos\n",
    "targets_problematicos = ['intensidad_termicas_mean_ms', 'tasa_ascenso_mean_ms']\n",
    "\n",
    "print(f\"Dev: {dev.shape}, Test: {test.shape}\")\n",
    "print(f\"Targets: {len(targets_reg)}\")\n",
    "print(f\"Targets problemáticos: {targets_problematicos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparar Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features simples (14 promedios)\n",
    "X_dev, y_dev, X_test, y_test = preparar_datos(dev, test, targets_reg, modo='simple')\n",
    "\n",
    "print(f\"Features: {X_dev.shape[1]}\")\n",
    "print(f\"Samples - Dev: {X_dev.shape[0]}, Test: {X_test.shape[0]}\")\n",
    "print(f\"Ratio: {X_dev.shape[0]/X_dev.shape[1]:.1f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Grid de Hiperparámetros\n",
    "\n",
    "Explorar espacio sistemáticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid de búsqueda\n",
    "param_grid = {\n",
    "    'max_depth': [5, 8, 10, 12, 15, None],\n",
    "    'min_samples_leaf': [2, 5, 8, 10, 15],\n",
    "    'max_features': [0.2, 0.3, 0.5, 0.7, 'sqrt']\n",
    "}\n",
    "\n",
    "print(\"Grid de Hiperparámetros:\")\n",
    "print(f\"  max_depth: {param_grid['max_depth']}\")\n",
    "print(f\"  min_samples_leaf: {param_grid['min_samples_leaf']}\")\n",
    "print(f\"  max_features: {param_grid['max_features']}\")\n",
    "print(f\"\\nCombinaciones totales: {len(param_grid['max_depth']) * len(param_grid['min_samples_leaf']) * len(param_grid['max_features'])}\")\n",
    "print(\"\\n⚠️ Esto tomará tiempo (~10-15 min)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Grid Search en Targets Problemáticos\n",
    "\n",
    "Primero optimizar para los que NO funcionan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_grid = {}\n",
    "mejores_params = {}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GRID SEARCH - TARGETS PROBLEMÁTICOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for target in targets_problematicos:\n",
    "    print(f\"\\n{target}:\")\n",
    "    t0 = time()\n",
    "    \n",
    "    # Grid Search con CV\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        rf,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='r2',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_dev, y_dev[target])\n",
    "    \n",
    "    # Guardar resultados\n",
    "    resultados_grid[target] = pd.DataFrame(grid_search.cv_results_)\n",
    "    mejores_params[target] = grid_search.best_params_\n",
    "    \n",
    "    print(f\"  Mejor CV R²: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"  Mejores params: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Evaluar en test\n",
    "    y_pred_test = grid_search.predict(X_test)\n",
    "    r2_test = evaluar_modelo(y_test[target], y_pred_test, target)['R2']\n",
    "    \n",
    "    print(f\"  Test R²: {r2_test:.4f}\")\n",
    "    print(f\"  Tiempo: {time()-t0:.1f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Grid Search en TODOS los Targets\n",
    "\n",
    "Buscar configuración óptima general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid más reducido para todos los targets\n",
    "param_grid_reduced = {\n",
    "    'max_depth': [8, 10, 12],\n",
    "    'min_samples_leaf': [5, 8, 10],\n",
    "    'max_features': [0.2, 0.3, 0.5]\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GRID SEARCH - TODOS LOS TARGETS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Grid reducido: {len(param_grid_reduced['max_depth']) * len(param_grid_reduced['min_samples_leaf']) * len(param_grid_reduced['max_features'])} combinaciones\\n\")\n",
    "\n",
    "resultados_todos = []\n",
    "\n",
    "for target in targets_reg:\n",
    "    print(f\"\\n{target}:\")\n",
    "    t0 = time()\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        rf,\n",
    "        param_grid_reduced,\n",
    "        cv=5,\n",
    "        scoring='r2',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_dev, y_dev[target])\n",
    "    \n",
    "    # Evaluar en test\n",
    "    y_pred_dev = grid_search.predict(X_dev)\n",
    "    y_pred_test = grid_search.predict(X_test)\n",
    "    \n",
    "    r2_dev = evaluar_modelo(y_dev[target], y_pred_dev, target)['R2']\n",
    "    r2_test = evaluar_modelo(y_test[target], y_pred_test, target)['R2']\n",
    "    \n",
    "    resultados_todos.append({\n",
    "        'target': target,\n",
    "        'CV_R2': grid_search.best_score_,\n",
    "        'Dev_R2': r2_dev,\n",
    "        'Test_R2': r2_test,\n",
    "        'Gap': r2_dev - r2_test,\n",
    "        'max_depth': grid_search.best_params_['max_depth'],\n",
    "        'min_samples_leaf': grid_search.best_params_['min_samples_leaf'],\n",
    "        'max_features': grid_search.best_params_['max_features']\n",
    "    })\n",
    "    \n",
    "    print(f\"  CV: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"  Test: {r2_test:.4f}\")\n",
    "    print(f\"  Params: {grid_search.best_params_}\")\n",
    "    print(f\"  Tiempo: {time()-t0:.1f}s\")\n",
    "\n",
    "df_todos = pd.DataFrame(resultados_todos)\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análisis de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ANÁLISIS: Hiperparámetros Óptimos por Target\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n\" + df_todos.sort_values('Test_R2', ascending=False).to_string(index=False))\n",
    "\n",
    "# Hiperparámetros más comunes\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FRECUENCIA DE HIPERPARÁMETROS:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nmax_depth:\")\n",
    "print(df_todos['max_depth'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nmin_samples_leaf:\")\n",
    "print(df_todos['min_samples_leaf'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nmax_features:\")\n",
    "print(df_todos['max_features'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico: R² Test vs Hiperparámetros\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# max_depth\n",
    "ax = axes[0]\n",
    "df_todos.groupby('max_depth')['Test_R2'].mean().plot(kind='bar', ax=ax, alpha=0.7)\n",
    "ax.set_xlabel('max_depth')\n",
    "ax.set_ylabel('R² Test (promedio)')\n",
    "ax.set_title('Impacto de max_depth')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# min_samples_leaf\n",
    "ax = axes[1]\n",
    "df_todos.groupby('min_samples_leaf')['Test_R2'].mean().plot(kind='bar', ax=ax, alpha=0.7)\n",
    "ax.set_xlabel('min_samples_leaf')\n",
    "ax.set_ylabel('R² Test (promedio)')\n",
    "ax.set_title('Impacto de min_samples_leaf')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# max_features\n",
    "ax = axes[2]\n",
    "df_todos.groupby('max_features')['Test_R2'].mean().plot(kind='bar', ax=ax, alpha=0.7)\n",
    "ax.set_xlabel('max_features')\n",
    "ax.set_ylabel('R² Test (promedio)')\n",
    "ax.set_title('Impacto de max_features')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/tuning_hiperparametros.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Recomendación Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración recomendada\n",
    "max_depth_rec = df_todos.groupby('max_depth')['Test_R2'].mean().idxmax()\n",
    "min_samples_leaf_rec = df_todos.groupby('min_samples_leaf')['Test_R2'].mean().idxmax()\n",
    "max_features_rec = df_todos.groupby('max_features')['Test_R2'].mean().idxmax()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RECOMENDACIÓN FINAL\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nHiperparámetros óptimos (basado en promedio de R² Test):\")\n",
    "print(f\"  max_depth: {max_depth_rec}\")\n",
    "print(f\"  min_samples_leaf: {min_samples_leaf_rec}\")\n",
    "print(f\"  max_features: {max_features_rec}\")\n",
    "\n",
    "# R² esperado con estos parámetros\n",
    "r2_promedio = df_todos['Test_R2'].mean()\n",
    "print(f\"\\nR² Test promedio: {r2_promedio:.4f}\")\n",
    "\n",
    "# Targets problemáticos\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TARGETS PROBLEMÁTICOS:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for target in targets_problematicos:\n",
    "    row = df_todos[df_todos['target']==target].iloc[0]\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  Test R²: {row['Test_R2']:.4f}\")\n",
    "    print(f\"  Params: max_depth={row['max_depth']}, min_samples_leaf={row['min_samples_leaf']}, max_features={row['max_features']}\")\n",
    "    \n",
    "    if row['Test_R2'] > 0.1:\n",
    "        print(f\"  ✓ MEJORÓ con tuning\")\n",
    "    else:\n",
    "        print(f\"  ❌ No predecible con features meteorológicas\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Guardar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_todos.to_csv('../data/processed/tuning_resultados.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ARCHIVOS GUARDADOS\")\n",
    "print(\"=\"*70)\n",
    "print(\"  - data/processed/tuning_resultados.csv\")\n",
    "print(\"  - data/processed/tuning_hiperparametros.png\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ TUNING DE HIPERPARÁMETROS COMPLETADO\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
