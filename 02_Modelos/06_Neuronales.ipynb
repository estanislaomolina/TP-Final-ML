{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8898bacc",
   "metadata": {},
   "source": [
    "# LSTM & Redes Neuronales\n",
    "En esta sección se realizara buscara darle una solucion al problema por medio de un combinacion de una Long Short Term Memory (LSTM) y una Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ac5789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d3b3bd",
   "metadata": {},
   "source": [
    "# Cargo los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9009cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando device: cpu\n"
     ]
    }
   ],
   "source": [
    "X_dev_full = pd.read_csv('../data/split/X_dev_full.csv', index_col=0)\n",
    "X_test_full = pd.read_csv('../data/split/X_test_full.csv', index_col=0)\n",
    "y_dev = pd.read_csv('../data/split/y_dev.csv', index_col=0)\n",
    "y_test = pd.read_csv('../data/split/y_test.csv', index_col=0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Usando device:\", device)\n",
    "\n",
    "# Targets que querés predecir\n",
    "target_cols = [\n",
    "    \"altura_max_m\",\n",
    "    \"ganancia_altura_m\",\n",
    "    \"duracion_min\",\n",
    "    \"distancia_km\",\n",
    "    \"velocidad_promedio_kmh\",\n",
    "    \"num_termicas\",\n",
    "    \"intensidad_termicas_mean_ms\",\n",
    "    \"tiempo_en_termicas_min\",\n",
    "    \"tasa_ascenso_mean_ms\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "464b15b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables secuenciales por timestep: ['boundary_layer_height', 'cape', 'cloud_cover', 'precipitation', 'pressure', 'skin_temp', 'solar_rad', 'temp_2m', 'wind_speed', 'wind_u', 'wind_v']\n",
      "Horas: ['09h', '10h', '11h', '12h', '13h', '14h', '15h', '16h', '17h', '18h']\n",
      "N seq features por timestep: 11\n",
      "N static features: 15\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 3) DEFINIR COLUMNAS SECUENCIALES Y ESTÁTICAS\n",
    "# ==============================\n",
    "\n",
    "cols = X_dev_full.columns.tolist()\n",
    "\n",
    "# Horas del 09h al 18h\n",
    "hours = [f\"{h:02d}h\" for h in range(9, 19)]  # ['09h', ..., '18h']\n",
    "\n",
    "# Columnas que terminan en _09h, ..., _18h → secuenciales\n",
    "seq_cols = [c for c in cols if any(c.endswith(f\"_{h}\") for h in hours)]\n",
    "\n",
    "# Prefijos de clima, ej: 'solar_rad', 'temp_2m', etc.\n",
    "prefixes = sorted({c.rsplit(\"_\", 1)[0] for c in seq_cols})\n",
    "\n",
    "# Grupos por timestep: para cada hora, todas las variables de clima\n",
    "seq_col_groups = [\n",
    "    [f\"{p}_{h}\" for p in prefixes]\n",
    "    for h in hours\n",
    "]\n",
    "\n",
    "# Columnas estáticas: todo lo que no es secuencial\n",
    "static_cols = [c for c in cols if c not in seq_cols]\n",
    "\n",
    "print(\"Variables secuenciales por timestep:\", prefixes)\n",
    "print(\"Horas:\", hours)\n",
    "print(\"N seq features por timestep:\", len(prefixes))\n",
    "print(\"N static features:\", len(static_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8d09a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 4) DATASET DE PYTORCH\n",
    "# ==============================\n",
    "\n",
    "class FlightLSTMDataset(Dataset):\n",
    "    def __init__(self, X_df, y_df, seq_col_groups, static_cols, target_cols):\n",
    "        self.X = X_df.reset_index(drop=True)\n",
    "        self.y_df = y_df.reset_index(drop=True)\n",
    "        self.seq_col_groups = seq_col_groups\n",
    "        self.static_cols = static_cols\n",
    "        self.target_cols = target_cols\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def _row_to_seq(self, row):\n",
    "        \"\"\"\n",
    "        Devuelve un tensor (T, F) sin usar numpy → sólo listas de Python.\n",
    "        T = nº timesteps (10: 09h..18h)\n",
    "        F = nº variables por timestep (len(prefixes))\n",
    "        \"\"\"\n",
    "        seq_list = []\n",
    "        for group in self.seq_col_groups:\n",
    "            # row[group] es una Series de pandas\n",
    "            vals = row[group].astype(\"float32\").tolist()  # list[float]\n",
    "            seq_list.append(vals)  # list[list[float]]\n",
    "\n",
    "        # Ahora seq_list es una lista de listas → torch.tensor puede manejarlo sin numpy\n",
    "        seq = torch.tensor(seq_list, dtype=torch.float32)  # (T, F)\n",
    "        return seq\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.X.iloc[idx]\n",
    "\n",
    "        # Secuencia (T, F)\n",
    "        seq = self._row_to_seq(row)\n",
    "\n",
    "        # Features estáticas (S,)\n",
    "        static_vals = row[self.static_cols].astype(\"float32\").tolist()\n",
    "        static = torch.tensor(static_vals, dtype=torch.float32)\n",
    "\n",
    "        # Targets (n_targets,)\n",
    "        y_row = self.y_df.iloc[idx][self.target_cols].astype(\"float32\").tolist()\n",
    "        y = torch.tensor(y_row, dtype=torch.float32)\n",
    "\n",
    "        return seq, static, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ebbf21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 5) MODELO LSTM + MLP\n",
    "# ==============================\n",
    "\n",
    "class ClimateLSTMRegressor(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_input_dim: int,\n",
    "        static_dim: int,\n",
    "        n_targets: int,\n",
    "        hidden_dim: int = 64,\n",
    "        num_layers: int = 1,\n",
    "        bidirectional: bool = True,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=seq_input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "\n",
    "        lstm_out_dim = hidden_dim * (2 if bidirectional else 1)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(lstm_out_dim + static_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, n_targets),\n",
    "        )\n",
    "\n",
    "    def forward(self, seq, static):\n",
    "        # seq: (batch, T, F), static: (batch, S)\n",
    "        _, (h_n, _) = self.lstm(seq)  # h_n: (num_layers*num_dirs, batch, hidden_dim)\n",
    "\n",
    "        if self.bidirectional:\n",
    "            h_forward = h_n[-2]   # (batch, hidden_dim)\n",
    "            h_backward = h_n[-1]  # (batch, hidden_dim)\n",
    "            h_last = torch.cat([h_forward, h_backward], dim=1)  # (batch, 2*hidden_dim)\n",
    "        else:\n",
    "            h_last = h_n[-1]  # (batch, hidden_dim)\n",
    "\n",
    "        x = torch.cat([h_last, static], dim=1)  # (batch, lstm_out_dim + static_dim)\n",
    "        out = self.mlp(x)  # (batch, n_targets)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a022e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 6) FUNCIONES DE TRAIN / EVAL\n",
    "# ==============================\n",
    "\n",
    "def run_epoch(model, loader, optimizer=None, device=device):\n",
    "    train = optimizer is not None\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    all_y = []\n",
    "    all_pred = []\n",
    "\n",
    "    for seq, static, y in loader:\n",
    "        seq = seq.to(device)\n",
    "        static = static.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            pred = model(seq, static)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        all_y.append(y.detach().cpu())\n",
    "        all_pred.append(pred.detach().cpu())\n",
    "\n",
    "    total_loss /= len(loader.dataset)\n",
    "    all_y = torch.cat(all_y, dim=0).numpy()       # (N, n_targets)\n",
    "    all_pred = torch.cat(all_pred, dim=0).numpy() # (N, n_targets)\n",
    "\n",
    "    # R² por target y promedio\n",
    "    r2_raw = r2_score(all_y, all_pred, multioutput=\"raw_values\")\n",
    "    r2_mean = float(np.mean(r2_raw))\n",
    "    return total_loss, r2_mean, r2_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4e4e82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FOLD 1/5\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m history_val_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 64\u001b[0m     train_loss, train_r2, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     val_loss, val_r2, _ \u001b[38;5;241m=\u001b[39m run_epoch(model, val_loader, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# Guardar historial\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[29], line 40\u001b[0m, in \u001b[0;36mrun_epoch\u001b[0;34m(model, loader, optimizer, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m     all_pred\u001b[38;5;241m.\u001b[39mappend(pred\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m     39\u001b[0m total_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(loader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[0;32m---> 40\u001b[0m all_y \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m       \u001b[38;5;66;03m# (N, n_targets)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m all_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(all_pred, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;66;03m# (N, n_targets)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# R² por target y promedio\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 7) CROSS-VALIDATION (K-FOLD) + CURVAS DE APRENDIZAJE\n",
    "# ==============================\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "n_splits = 5\n",
    "batch_size = 32\n",
    "n_epochs = 40\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-5\n",
    "\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "seq_input_dim = len(prefixes)\n",
    "static_dim = len(static_cols)\n",
    "n_targets = len(target_cols)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_dev_full)):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"FOLD {fold+1}/{n_splits}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Split por índices\n",
    "    X_tr = X_dev_full.iloc[train_idx].reset_index(drop=True)\n",
    "    y_tr = y_dev.iloc[train_idx].reset_index(drop=True)\n",
    "    X_va = X_dev_full.iloc[val_idx].reset_index(drop=True)\n",
    "    y_va = y_dev.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    # Datasets y loaders\n",
    "    train_ds = FlightLSTMDataset(X_tr, y_tr, seq_col_groups, static_cols, target_cols)\n",
    "    val_ds   = FlightLSTMDataset(X_va, y_va, seq_col_groups, static_cols, target_cols)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size*2, shuffle=False)\n",
    "\n",
    "    # Re-inicializar modelo y optimizador en cada fold\n",
    "    model = ClimateLSTMRegressor(\n",
    "        seq_input_dim=seq_input_dim,\n",
    "        static_dim=static_dim,\n",
    "        n_targets=n_targets,\n",
    "        hidden_dim=64,\n",
    "        num_layers=1,\n",
    "        bidirectional=True,\n",
    "        dropout=0.1,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    best_val_r2 = -1e9\n",
    "    best_state = None\n",
    "\n",
    "    # Historial para curvas de aprendizaje\n",
    "    history_train_r2 = []\n",
    "    history_val_r2 = []\n",
    "    history_train_loss = []\n",
    "    history_val_loss = []\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss, train_r2, _ = run_epoch(model, train_loader, optimizer=optimizer)\n",
    "        val_loss, val_r2, _ = run_epoch(model, val_loader, optimizer=None)\n",
    "\n",
    "        # Guardar historial\n",
    "        history_train_r2.append(train_r2)\n",
    "        history_val_r2.append(val_r2)\n",
    "        history_train_loss.append(train_loss)\n",
    "        history_val_loss.append(val_loss)\n",
    "\n",
    "        # Guardar mejor modelo (por R² de validación promedio)\n",
    "        if val_r2 > best_val_r2:\n",
    "            best_val_r2 = val_r2\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            print(\n",
    "                f\"Epoch {epoch:03d} | \"\n",
    "                f\"Train Loss={train_loss:.3f}, R2={train_r2:.3f} | \"\n",
    "                f\"Val Loss={val_loss:.3f}, R2={val_r2:.3f}\"\n",
    "            )\n",
    "\n",
    "    # ---- CURVAS DE APRENDIZAJE PARA ESTE FOLD ----\n",
    "    epochs_axis = range(1, n_epochs + 1)\n",
    "\n",
    "    # R²\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(epochs_axis, history_train_r2, label=\"Train R²\")\n",
    "    plt.plot(epochs_axis, history_val_r2, label=\"Val R²\")\n",
    "    plt.xlabel(\"Época\")\n",
    "    plt.ylabel(\"R²\")\n",
    "    plt.title(f\"Curva de aprendizaje R² - Fold {fold+1}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Loss (MSE)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(epochs_axis, history_train_loss, label=\"Train Loss\")\n",
    "    plt.plot(epochs_axis, history_val_loss, label=\"Val Loss\")\n",
    "    plt.xlabel(\"Época\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.title(f\"Curva de aprendizaje Loss - Fold {fold+1}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ---- Evaluar el mejor estado del fold en el set de validación ----\n",
    "    model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n",
    "    _, val_r2_final, val_r2_targets = run_epoch(model, val_loader, optimizer=None)\n",
    "\n",
    "    print(\"\\nMejor R² de validación (promedio targets):\", f\"{val_r2_final:.4f}\")\n",
    "    print(\"R² por target en este fold:\")\n",
    "    for name, r2v in zip(target_cols, val_r2_targets):\n",
    "        print(f\"  {name:30s}: {r2v:.4f}\")\n",
    "\n",
    "    fold_results.append(val_r2_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f50050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 8) RESUMEN FINAL DE CV\n",
    "# ==============================\n",
    "\n",
    "fold_results = np.vstack(fold_results)  # shape (n_splits, n_targets)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUMEN CROSS-VALIDATION (LSTM+MLP)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "mean_r2_targets = fold_results.mean(axis=0)\n",
    "std_r2_targets = fold_results.std(axis=0)\n",
    "\n",
    "for name, mu, sd in zip(target_cols, mean_r2_targets, std_r2_targets):\n",
    "    print(f\"{name:30s}: R² CV medio = {mu:.4f} ± {sd:.4f}\")\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(\"R² CV PROMEDIO (sobre todos los targets):\", f\"{mean_r2_targets.mean():.4f}\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
