{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regularizado\n",
    "## Predicci√≥n de Caracter√≠sticas de Vuelo en Planeador\n",
    "\n",
    "**Objetivo:** Mejorar sobre baseline con Random Forest regularizado\n",
    "\n",
    "**Autor:** Estanislao  \n",
    "**Fecha:** Diciembre 2024\n",
    "\n",
    "---\n",
    "\n",
    "## Estrategia Anti-Overfitting\n",
    "\n",
    "- `max_depth=10`: Limitar profundidad de √°rboles\n",
    "- `min_samples_leaf=5`: M√≠nimo 5 muestras por hoja\n",
    "- `max_features=0.3`: Solo 30% features por √°rbol\n",
    "- Cross-validation para validar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'eda_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[1;32m     12\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../utils\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meda_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configurar_visualizacion\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodelo_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preparar_datos, evaluar_modelo\n\u001b[1;32m     16\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'eda_functions'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sys.path.append('../01_Preprocesamiento')\n",
    "from eda_functions import configurar_visualizacion\n",
    "from modelo_utils import preparar_datos, evaluar_modelo\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "configurar_visualizacion()\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.read_csv('../data/processed/dev.csv', index_col=0)\n",
    "test = pd.read_csv('../data/processed/test.csv', index_col=0)\n",
    "\n",
    "targets_reg = [\n",
    "    'altura_max_m', 'ganancia_altura_m', 'duracion_min',\n",
    "    'distancia_km', 'velocidad_promedio_kmh', 'num_termicas',\n",
    "    'intensidad_termicas_mean_ms', 'tiempo_en_termicas_min',\n",
    "    'tasa_ascenso_mean_ms'\n",
    "]\n",
    "\n",
    "print(f\"Dev: {dev.shape}, Test: {test.shape}\")\n",
    "print(f\"Targets: {len(targets_reg)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparar Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar modo simple (solo promedios)\n",
    "X_dev, y_dev, X_test, y_test = preparar_datos(dev, test, targets_reg, modo='simple')\n",
    "\n",
    "print(f\"\\nFeatures: {X_dev.shape[1]}\")\n",
    "print(f\"Samples - Dev: {X_dev.shape[0]}, Test: {X_test.shape[0]}\")\n",
    "print(f\"Ratio: {X_dev.shape[0]/X_dev.shape[1]:.1f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forest Regularizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_rf = []\n",
    "modelos_rf = {}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RANDOM FOREST - REGULARIZADO\")\n",
    "print(\"=\"*70)\n",
    "print(\"max_depth=10, min_samples_leaf=5, max_features=0.3\\n\")\n",
    "\n",
    "for target in targets_reg:\n",
    "    print(f\"\\n{target}:\")\n",
    "    t0 = time()\n",
    "    \n",
    "    # Modelo regularizado\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_leaf=5,\n",
    "        max_features=0.3,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(rf, X_dev, y_dev[target], \n",
    "                                cv=5, scoring='r2', n_jobs=-1)\n",
    "    \n",
    "    # Entrenar en todo Dev\n",
    "    rf.fit(X_dev, y_dev[target])\n",
    "    modelos_rf[target] = rf\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred_dev = rf.predict(X_dev)\n",
    "    y_pred_test = rf.predict(X_test)\n",
    "    \n",
    "    # M√©tricas\n",
    "    metrics_dev = evaluar_modelo(y_dev[target], y_pred_dev, target)\n",
    "    metrics_dev['split'] = 'Dev'\n",
    "    metrics_dev['CV_mean'] = cv_scores.mean()\n",
    "    metrics_dev['CV_std'] = cv_scores.std()\n",
    "    \n",
    "    metrics_test = evaluar_modelo(y_test[target], y_pred_test, target)\n",
    "    metrics_test['split'] = 'Test'\n",
    "    metrics_test['CV_mean'] = cv_scores.mean()\n",
    "    metrics_test['CV_std'] = cv_scores.std()\n",
    "    \n",
    "    resultados_rf.append(metrics_dev)\n",
    "    resultados_rf.append(metrics_test)\n",
    "    \n",
    "    # Calcular gap\n",
    "    gap = metrics_dev['R2'] - metrics_test['R2']\n",
    "    status = \"üö®\" if gap > 0.3 else (\"‚ö†Ô∏è\" if gap > 0.15 else \"‚úì\")\n",
    "    \n",
    "    print(f\"  CV:   {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
    "    print(f\"  Dev:  {metrics_dev['R2']:.4f}\")\n",
    "    print(f\"  Test: {metrics_test['R2']:.4f}\")\n",
    "    print(f\"  Gap:  {gap:.4f} {status}\")\n",
    "    print(f\"  Tiempo: {time()-t0:.1f}s\")\n",
    "\n",
    "df_rf = pd.DataFrame(resultados_rf)\n",
    "df_rf['modelo'] = 'RandomForest'\n",
    "\n",
    "# Clipear R¬≤ negativos\n",
    "df_rf['R2'] = df_rf['R2'].clip(lower=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparaci√≥n con Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar baseline\n",
    "df_baseline = pd.read_csv('../data/processed/resultados_hibrido.csv')\n",
    "\n",
    "# Comparar solo Ridge/Dummy vs RF\n",
    "df_comp = pd.concat([df_baseline, df_rf], ignore_index=True)\n",
    "df_test_comp = df_comp[df_comp['split'] == 'Test'].copy()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"COMPARACI√ìN: Baseline vs Random Forest (Test)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for target in targets_reg:\n",
    "    r2_base = df_test_comp[df_test_comp['target']==target]['R2'].iloc[0]\n",
    "    r2_rf = df_test_comp[df_test_comp['target']==target]['R2'].iloc[1]\n",
    "    mejora = r2_rf - r2_base\n",
    "    \n",
    "    status = \"‚úì‚úì\" if mejora > 0.05 else (\"‚úì\" if mejora > 0 else \"‚Üí\")\n",
    "    \n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  Baseline: {r2_base:.4f}\")\n",
    "    print(f\"  RF:       {r2_rf:.4f}\")\n",
    "    print(f\"  Mejora:   {mejora:+.4f} {status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 features por target\n",
    "print(\"=\"*70)\n",
    "print(\"FEATURE IMPORTANCE (Top 5 por target)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for target in targets_reg:\n",
    "    rf = modelos_rf[target]\n",
    "    importances = pd.DataFrame({\n",
    "        'feature': X_dev.columns,\n",
    "        'importance': rf.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\n{target}:\")\n",
    "    for _, row in importances.head(5).iterrows():\n",
    "        print(f\"  {row['feature']:30s}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico comparativo\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "x = np.arange(len(targets_reg))\n",
    "width = 0.35\n",
    "\n",
    "r2_baseline = []\n",
    "r2_rf = []\n",
    "\n",
    "for target in targets_reg:\n",
    "    r2_base = df_test_comp[df_test_comp['target']==target]['R2'].iloc[0]\n",
    "    r2_forest = df_test_comp[df_test_comp['target']==target]['R2'].iloc[1]\n",
    "    r2_baseline.append(r2_base)\n",
    "    r2_rf.append(r2_forest)\n",
    "\n",
    "ax.bar(x - width/2, r2_baseline, width, label='Baseline', alpha=0.7)\n",
    "ax.bar(x + width/2, r2_rf, width, label='Random Forest', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Target', fontsize=12)\n",
    "ax.set_ylabel('R¬≤', fontsize=12)\n",
    "ax.set_title('Baseline vs Random Forest - R¬≤ en Test', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(targets_reg, rotation=45, ha='right')\n",
    "ax.legend(fontsize=11)\n",
    "ax.axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/rf_vs_baseline.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Guardar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf.to_csv('../data/processed/resultados_rf.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ARCHIVOS GUARDADOS\")\n",
    "print(\"=\"*70)\n",
    "print(\"  - data/processed/resultados_rf.csv\")\n",
    "print(\"  - data/processed/rf_vs_baseline.png\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì RANDOM FOREST (FEATURES SIMPLES) COMPLETADO\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PARTE 2: Random Forest con Features COMPLETAS\n",
    "\n",
    "Probar si features horarias (09h-18h) mejoran targets problem√°ticos:\n",
    "- intensidad_termicas_mean_ms\n",
    "- tasa_ascenso_mean_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Preparar Features Completas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar TODAS las features horarias\n",
    "X_dev_full, y_dev_full, X_test_full, y_test_full = preparar_datos(\n",
    "    dev, test, targets_reg, modo='completo'\n",
    ")\n",
    "\n",
    "print(f\"\\nFeatures COMPLETAS: {X_dev_full.shape[1]}\")\n",
    "print(f\"Samples - Dev: {X_dev_full.shape[0]}, Test: {X_test_full.shape[0]}\")\n",
    "print(f\"Ratio: {X_dev_full.shape[0]/X_dev_full.shape[1]:.1f}:1\")\n",
    "print(f\"\\n‚ö†Ô∏è Ratio bajo - regularizaci√≥n m√°s agresiva necesaria\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. RF con Features Completas (REGULARIZACI√ìN AGRESIVA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_rf_full = []\n",
    "modelos_rf_full = {}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RANDOM FOREST - FEATURES COMPLETAS (110+)\")\n",
    "print(\"=\"*70)\n",
    "print(\"max_depth=8, min_samples_leaf=8, max_features=0.2 (m√°s restrictivo)\\n\")\n",
    "\n",
    "for target in targets_reg:\n",
    "    print(f\"\\n{target}:\")\n",
    "    t0 = time()\n",
    "    \n",
    "    # Regularizaci√≥n M√ÅS AGRESIVA (ratio bajo)\n",
    "    rf_full = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=8,           # M√°s bajo que antes\n",
    "        min_samples_leaf=8,    # M√°s alto que antes\n",
    "        max_features=0.2,      # Menos features por √°rbol\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(rf_full, X_dev_full, y_dev_full[target],\n",
    "                                cv=5, scoring='r2', n_jobs=-1)\n",
    "    \n",
    "    # Entrenar\n",
    "    rf_full.fit(X_dev_full, y_dev_full[target])\n",
    "    modelos_rf_full[target] = rf_full\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred_dev = rf_full.predict(X_dev_full)\n",
    "    y_pred_test = rf_full.predict(X_test_full)\n",
    "    \n",
    "    # M√©tricas\n",
    "    metrics_dev = evaluar_modelo(y_dev_full[target], y_pred_dev, target)\n",
    "    metrics_dev['split'] = 'Dev'\n",
    "    metrics_dev['CV_mean'] = cv_scores.mean()\n",
    "    metrics_dev['CV_std'] = cv_scores.std()\n",
    "    \n",
    "    metrics_test = evaluar_modelo(y_test_full[target], y_pred_test, target)\n",
    "    metrics_test['split'] = 'Test'\n",
    "    metrics_test['CV_mean'] = cv_scores.mean()\n",
    "    metrics_test['CV_std'] = cv_scores.std()\n",
    "    \n",
    "    resultados_rf_full.append(metrics_dev)\n",
    "    resultados_rf_full.append(metrics_test)\n",
    "    \n",
    "    # Gap\n",
    "    gap = metrics_dev['R2'] - metrics_test['R2']\n",
    "    status = \"üö®\" if gap > 0.3 else (\"‚ö†Ô∏è\" if gap > 0.15 else \"‚úì\")\n",
    "    \n",
    "    print(f\"  CV:   {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
    "    print(f\"  Dev:  {metrics_dev['R2']:.4f}\")\n",
    "    print(f\"  Test: {metrics_test['R2']:.4f}\")\n",
    "    print(f\"  Gap:  {gap:.4f} {status}\")\n",
    "    print(f\"  Tiempo: {time()-t0:.1f}s\")\n",
    "\n",
    "df_rf_full = pd.DataFrame(resultados_rf_full)\n",
    "df_rf_full['modelo'] = 'RF_Full'\n",
    "df_rf_full['R2'] = df_rf_full['R2'].clip(lower=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Comparaci√≥n: RF Simple vs RF Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"COMPARACI√ìN: RF Simple (14 features) vs RF Full (110+ features)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "mejoras = []\n",
    "\n",
    "for target in targets_reg:\n",
    "    r2_simple = df_rf[(df_rf['target']==target) & (df_rf['split']=='Test')]['R2'].values[0]\n",
    "    r2_full = df_rf_full[(df_rf_full['target']==target) & (df_rf_full['split']=='Test')]['R2'].values[0]\n",
    "    \n",
    "    gap_simple = df_rf[(df_rf['target']==target) & (df_rf['split']=='Dev')]['R2'].values[0] - r2_simple\n",
    "    gap_full = df_rf_full[(df_rf_full['target']==target) & (df_rf_full['split']=='Dev')]['R2'].values[0] - r2_full\n",
    "    \n",
    "    mejora = r2_full - r2_simple\n",
    "    mejoras.append({'target': target, 'mejora': mejora})\n",
    "    \n",
    "    status = \"‚úì‚úì\" if mejora > 0.05 else (\"‚úì\" if mejora > 0 else (\"‚Üí\" if mejora > -0.05 else \"‚ùå\"))\n",
    "    \n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  Simple (14): {r2_simple:.4f} (gap: {gap_simple:.3f})\")\n",
    "    print(f\"  Full (110):  {r2_full:.4f} (gap: {gap_full:.3f})\")\n",
    "    print(f\"  Mejora:      {mejora:+.4f} {status}\")\n",
    "\n",
    "df_mejoras = pd.DataFrame(mejoras).sort_values('mejora', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUMEN:\")\n",
    "print(\"=\"*70)\n",
    "mejoraron = len(df_mejoras[df_mejoras['mejora'] > 0])\n",
    "empeoraron = len(df_mejoras[df_mejoras['mejora'] < 0])\n",
    "print(f\"Mejoraron: {mejoraron}/9\")\n",
    "print(f\"Empeoraron: {empeoraron}/9\")\n",
    "\n",
    "if mejoraron > 5:\n",
    "    print(\"\\n‚úì‚úì FEATURES COMPLETAS FUNCIONAN MEJOR\")\n",
    "elif empeoraron > 5:\n",
    "    print(\"\\n‚ùå OVERFITTING - Usar features simples\")\n",
    "else:\n",
    "    print(\"\\n‚Üí RESULTADOS MIXTOS - Analizar caso por caso\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Guardar Resultados Completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf_full.to_csv('../data/processed/resultados_rf_full.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ARCHIVOS GUARDADOS\")\n",
    "print(\"=\"*70)\n",
    "print(\"  - data/processed/resultados_rf_full.csv\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì RANDOM FOREST (FEATURES COMPLETAS) COMPLETADO\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
